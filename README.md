# RAG Visualizer

A comprehensive visualization system for understanding and debugging Retrieval-Augmented Generation (RAG) pipelines. This project provides interactive visualizations for document chunking, knowledge graph construction, and retrieval processes.

## ğŸ“ Project Structure

```
rag-visualizer/
â”œâ”€â”€ backend/                 # FastAPI backend service
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ core/           # Core RAG logic
â”‚   â”‚   â”‚   â”œâ”€â”€ chunking/   # Document chunking strategies
â”‚   â”‚   â”‚   â”œâ”€â”€ embedding/  # Embedding generation
â”‚   â”‚   â”‚   â”œâ”€â”€ retrieval/  # Retrieval strategies
â”‚   â”‚   â”‚   â”œâ”€â”€ graph/      # Knowledge graph extraction
â”‚   â”‚   â”‚   â””â”€â”€ temporal/   # Temporal processing
â”‚   â”‚   â”œâ”€â”€ services/       # Service layer
â”‚   â”‚   â”œâ”€â”€ storage/        # Database adapters
â”‚   â”‚   â””â”€â”€ models/         # Pydantic models
â”‚   â””â”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ frontend/               # React TypeScript frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”‚   â”œâ”€â”€ services/       # API client services
â”‚   â”‚   â””â”€â”€ types/          # TypeScript definitions
â”‚   â”œâ”€â”€ package.json        # Node dependencies
â”‚   â””â”€â”€ nixpacks.toml       # Railway deployment config
â”œâ”€â”€ scripts/                # Utility and management scripts
â”‚   â”œâ”€â”€ start.sh           # Start development servers
â”‚   â”œâ”€â”€ stop.sh            # Stop development servers
â”‚   â”œâ”€â”€ force_restart.sh   # Force restart services
â”‚   â”œâ”€â”€ create_tables.py   # Database initialization
â”‚   â””â”€â”€ setup_storage.py   # Storage setup
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ unit/              # Unit tests
â”‚   â”œâ”€â”€ integration/       # Integration tests
â”‚   â””â”€â”€ test_*.py          # Test files
â”œâ”€â”€ migrations/            # Database migrations
â”‚   â”œâ”€â”€ *.sql             # SQL migration files
â”‚   â””â”€â”€ *.cypher          # Neo4j schema files
â”œâ”€â”€ Dockerfile            # Backend Docker configuration
â”œâ”€â”€ railway.json          # Railway deployment config
â””â”€â”€ docker-compose.yml    # Local development infrastructure
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10+ with pip
- Node.js 18+ with npm or bun
- Docker and Docker Compose
- Git

### One-Command Start

```bash
# Start everything (backend + frontend)
./start.sh

# Stop everything
./stop.sh
```

The start script will:
- âœ… Start backend on http://localhost:8642
- âœ… Start frontend on http://localhost:5892
- âœ… Create log files for debugging
- âœ… Handle virtual environment activation

## ğŸ“œ Scripts

All management scripts are located in the `scripts/` directory:

### Development Scripts

| Script | Purpose | Usage |
|--------|---------|-------|
| `start.sh` | Start both backend and frontend | `./scripts/start.sh` or `./start.sh` |
| `stop.sh` | Stop all services cleanly | `./scripts/stop.sh` or `./stop.sh` |
| `force_restart.sh` | Force restart with clean state | `./scripts/force_restart.sh` |

### Setup Scripts

| Script | Purpose | Usage |
|--------|---------|-------|
| `create_tables.py` | Initialize database tables | `python scripts/create_tables.py` |
| `setup_storage.py` | Configure storage backends | `python scripts/setup_storage.py` |
| `run_tests.py` | Run test suite | `python scripts/run_tests.py` |

## ğŸ§ª Testing

### Test Coverage

Our test suite covers:

- **Unit Tests** (`tests/unit/`)
  - Date extraction and temporal processing
  - Query enhancement logic
  - Hybrid search algorithms
  - Graph RAG functionality

- **Integration Tests** (`tests/integration/`)
  - Fusion controller operations
  - End-to-end RAG pipeline
  - Service integrations

- **System Tests** (`tests/`)
  - Complete system functionality
  - Neo4j and Qdrant connections
  - Supabase integration
  - UI functionality testing

### Running Tests

```bash
# Run all tests
python scripts/run_tests.py

# Run specific test file
python -m pytest tests/test_services.py

# Run with coverage
python -m pytest --cov=backend/src tests/

# Run integration tests only
python -m pytest tests/integration/
```

## ğŸ—ï¸ Architecture

### Backend (FastAPI)

The backend is a FastAPI application with:

- **API Layer**: RESTful endpoints for all operations
- **Service Layer**: Business logic and orchestration
- **Storage Layer**: Abstractions for PostgreSQL, Qdrant, Neo4j
- **Core Components**:
  - Document processing and chunking
  - Entity and relationship extraction
  - Vector and graph-based retrieval
  - Temporal analysis
  - Query enhancement

### Frontend (React + TypeScript)

The frontend provides:

- **Interactive Visualizations**: D3.js and Cytoscape.js powered
- **Real-time Updates**: WebSocket support for live data
- **Component Library**:
  - ChunkVisualizer: Document chunk exploration
  - GraphViewer: Knowledge graph visualization
  - FusionControls: Retrieval strategy controls

## ğŸš¢ Deployment

### Railway Deployment

The project is configured for Railway deployment with:

1. **Backend Service** (Dockerfile)
   - Python 3.11 slim base image
   - Automatic spaCy model download
   - Environment variable support
   - Health check endpoint at `/health`

2. **Frontend Service** (nixpacks.toml)
   - Bun package manager for speed
   - Production build with Vite
   - Served with `serve` package
   - Port configuration via environment

### Environment Variables

Create `.env` file (see `.env.example`):

```bash
# Backend
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_key
AWS_SECRET_ACCESS_KEY=your_secret
SUPABASE_URL=your_url
SUPABASE_KEY=your_key
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Frontend (for Railway)
VITE_API_BASE=https://your-backend.railway.app
```

### Deployment Steps

1. **Push to GitHub**
   ```bash
   git add -A
   git commit -m "Deploy to Railway"
   git push origin main
   ```

2. **Railway Setup**
   - Create new project on Railway
   - Add backend service (point to Dockerfile)
   - Add frontend service (point to frontend/ directory)
   - Configure environment variables
   - Generate public domains for both services

3. **Configure Frontend**
   - Set `VITE_API_BASE` to backend's public URL
   - Set port to 8080 in Railway networking settings

## ğŸ”§ Development

### Backend Development

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download spaCy model
python -m spacy download en_core_web_sm

# Start development server
python -m uvicorn src.main:app --reload --port 8642
```

### Frontend Development

```bash
cd frontend

# Install dependencies (using bun for speed)
bun install
# OR using npm
npm install

# Start development server
bun run dev
# OR
npm run dev
```

### Database Setup

```bash
# Start local databases
docker-compose up -d

# Initialize tables
python scripts/create_tables.py

# Setup storage backends
python scripts/setup_storage.py
```

## ğŸ“Š Features

### Document Processing & Chunking
- **Multiple Strategies**: Standard, Hierarchical, and Semantic chunking
- **Visual Explorer**: Interactive chunk hierarchy visualization
- **Token Analysis**: Real-time token counting and overlap

### Knowledge Graph Construction
- **Entity Extraction**: NER and pattern-based recognition
- **Relationship Discovery**: Automatic relationship extraction
- **Graph Visualization**: Interactive force-directed graphs
- **Community Detection**: Visual clustering of entities

### Retrieval Pipeline
- **Hybrid Retrieval**: Vector + graph-based approaches
- **Query Analysis**: Real-time intent classification
- **Reranking**: Cross-encoder reranking visualization
- **Score Distribution**: Interactive retrieval score charts

### Temporal Analysis
- **Date Extraction**: Automatic temporal entity detection
- **Time-aware Retrieval**: Temporal relevance scoring
- **Decay Functions**: Configurable temporal decay curves

## ğŸ” API Endpoints

### Document Management
- `POST /api/documents` - Create document
- `POST /api/documents/upload` - Upload file
- `GET /api/documents` - List documents
- `GET /api/documents/{id}` - Get document

### Chunking
- `POST /api/chunking` - Chunk document
- `GET /api/documents/{id}/chunks` - Get chunks

### Graph Operations
- `POST /api/graph/extract` - Extract entities
- `GET /api/graph/{id}/entities` - Get entities
- `GET /api/graph/{id}/relationships` - Get relationships

### Query & Retrieval
- `POST /api/query` - Query documents
- `POST /api/fusion/search` - Fusion search

### Visualization
- `GET /api/visualization/{id}` - Get visualization data

## ğŸ› Troubleshooting

### Common Issues

1. **Port Already in Use**
   ```bash
   # Force stop all services
   ./scripts/force_restart.sh
   ./scripts/stop.sh
   ```

2. **Backend Won't Start**
   ```bash
   # Check logs
   tail -f backend.log
   
   # Verify virtual environment
   source venv/bin/activate
   pip install -r backend/requirements.txt
   ```

3. **Frontend Build Fails**
   ```bash
   # Clear cache and reinstall
   cd frontend
   rm -rf node_modules dist
   bun install
   bun run build
   ```

4. **Database Connection Issues**
   ```bash
   # Restart Docker containers
   docker-compose down
   docker-compose up -d
   
   # Check container status
   docker ps
   ```

### Log Files

- **Backend**: `backend.log`
- **Frontend**: `frontend.log`
- **Startup Debug**: `startup_debug.log`

Monitor logs in real-time:
```bash
tail -f backend.log
tail -f frontend.log
```

## ğŸ“ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Add/update tests as needed
5. Run test suite (`python scripts/run_tests.py`)
6. Commit changes (`git commit -m 'Add amazing feature'`)
7. Push to branch (`git push origin feature/amazing-feature`)
8. Open a Pull Request

## ğŸ“„ License

MIT License - see LICENSE file for details

## ğŸ™ Acknowledgments

- Based on SmartRAG research
- Powered by FastAPI and React
- Visualization with D3.js and Cytoscape.js
- NLP processing with spaCy
- Vector search with Qdrant
- Graph database with Neo4j